{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtyping\n",
    "\n",
    "#### Quick tutorial of runtime type-checking for PyTorch tensors, for deep learning practitioners. \n",
    "[`torchtyping` Github link](https://github.com/patrick-kidger/torchtyping/blob/master/README.md)\n",
    "\n",
    "(DISCLAIMER: I'm not the author of `torchtyping` and I'm not a programming language expert or type-theory afficionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtyping \n",
    "!pip install torch --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gripes\n",
    "\n",
    "#### Are you sick of tensor shape errors in your code?\n",
    "#### Do you want to more interpretable error messages on shape mismatches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "weight = torch.randn((4, 4))\n",
    "x = torch.randn((16, 4, 4))\n",
    "torch.bmm(weight, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn((1, 4, 4))\n",
    "x = torch.randn((16, 4, 4))\n",
    "torch.bmm(weight, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are you frustrated by poor tensor shape documentation?\n",
    "\n",
    "Done in code comments - if the code is ever commented at all.\n",
    "\n",
    "```python\n",
    "embed = Embedding(x) # [batch, seq, dim]    descriptive\n",
    "layer1 = Layer1(embed) # [b, s, d]          terse\n",
    "layer2 = Layer2(layer1) # batch first       what are the other dimensions?\n",
    "logits = FunkyLayer(layer2) #               no annotation at all!\n",
    "\n",
    "def foo(x: torch.Tensor) -> torch.Tensor: # very generic type annotations. like... obviously?\n",
    "    return x\n",
    "``` \n",
    "\n",
    "#### Are `asserts` your only defense against shape mismatches?\n",
    "\n",
    "```python\n",
    "HIDDEN_DIM = 1024\n",
    "logits = my_op(input)\n",
    "assert logits.size(-1) == HIDDEN_DIM\n",
    "```\n",
    "\n",
    "#### Are you lazy and only want to check shapes when you have to?\n",
    "\n",
    "```python\n",
    "def complex_tensor_wizardry_op(t):  # we want to document this!\n",
    "    ...\n",
    "\n",
    "def clamper(t):                     # not worth documenting or checking\n",
    "    return torch.clamp(t, max=1.0)\n",
    "```\n",
    "\n",
    "#### Do you want to check for valid shapes in unit tests before loading a massive model into memory?\n",
    "\n",
    "10 seconds to 10 minutes wasted on model loading, distributed training initialization, and priming data loaders only to find out that you transposed dims or forgot to `(un)squeeze`.\n",
    "\n",
    "#### Do you want to avoid the effort of annotating an entire codebase?\n",
    "\n",
    "C'mon, you want to spend your time running experiments - not tackling technical debt!\n",
    "\n",
    "#### What if you're locked to a particular Python or torch version and don't want to upgrade to get experimental support for named tensors?\n",
    "\n",
    "You're pinned to that golden PyTorch 1.2.0 Docker image that is the only one that works in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEHOLD [torchtyping](https://github.com/patrick-kidger/torchtyping)\n",
    "\n",
    "Turn this:\n",
    "\n",
    "```python\n",
    "def batch_outer_product(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    # x has shape (batch, x_channels)\n",
    "    # y has shape (batch, y_channels)\n",
    "    # return has shape (batch, x_channels, y_channels)\n",
    "\n",
    "    return x.unsqueeze(-1) * y.unsqueeze(-2)\n",
    "```\n",
    "\n",
    "into this:\n",
    "\n",
    "```python\n",
    "@typechecked\n",
    "def batch_outer_product(x:   TensorType[\"batch\", \"x_channels\"],\n",
    "                        y:   TensorType[\"batch\", \"y_channels\"]\n",
    "                        ) -> TensorType[\"batch\", \"x_channels\", \"y_channels\"]:\n",
    "\n",
    "    return x.unsqueeze(-1) * y.unsqueeze(-2)\n",
    "```\n",
    "\n",
    "(^ shamelessly stolen from the project's [readme](https://github.com/patrick-kidger/torchtyping/blob/master/README.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "Remember type annotations (\"type hints\") in Python are completely optional: __they aren't enforced statically or at runtime__.\n",
    "```python\n",
    "def foo(bar: int) -> int:\n",
    "    return 42\n",
    "```\n",
    "\n",
    "`mypy` allows **optional static** type-checking.\n",
    "\n",
    "Use `torchtyping`'s `patch_typeguard` in your module to enforce tensor type checking at **runtime**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtyping import TensorType, patch_typeguard\n",
    "from typeguard import typechecked\n",
    "\n",
    "patch_typeguard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **generic** type can be specified with a `TypeVar` and used as a type annotation. e.g.\n",
    "\n",
    "```python\n",
    "from typing import List\n",
    "x: List[int] = [1, 2, 3]\n",
    "```\n",
    "\n",
    "Tensors are multidimensional, so they can have a different generic type for each dimension/axis.\n",
    "\n",
    "We want something like this:\n",
    "\n",
    "```python\n",
    "x: Tensor['batch', 'seqlen', 'hidden'] = torch.randn((16, 128, 1024))\n",
    "```\n",
    "\n",
    "Tensors can also have layout and sparsity properties, as well as actual data type (`float64`, `int`, etc.).\n",
    "\n",
    "This specification is called a **variadic generic** type. \n",
    "Variadic generics were proposed in [PEP 646](https://peps.python.org/pep-0646/) and are [coming in Python 3.11](https://mail.python.org/archives/list/python-dev@python.org/message/OR5RKV7GAVSGLVH3JAGQ6OXFAXIP5XDX/)\n",
    "\n",
    "#### **`torchtyping` enables variadic generics for PyTorch tensors.**\n",
    "\n",
    "These can be used in function signatures or left-hand-side (LHS) type annotations.\n",
    "\n",
    "`torchtyping` can __enforce__ variadic generic types on function signatures at runtime or during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def mm(A: TensorType['m','n'], B: TensorType['m','p']) -> TensorType['n','p']:\n",
    "    return A.T @ B\n",
    "\n",
    "mm(torch.eye(3), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a `torchtyping` error look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm(torch.eye(4), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about matrix-vector multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm(torch.eye(4), torch.arange(4).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensortyping` has support for `Union` and `Optional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "@typechecked\n",
    "def mm2(A: TensorType['m', 'n'], B: Union[TensorType['m', 'p'], TensorType['m']] ) -> Union[TensorType['n',  'p'], TensorType['n']]:\n",
    "    return A.T @ B\n",
    "\n",
    "# matrix-vector\n",
    "mm2(torch.eye(3), torch.arange(3).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix-matrix\n",
    "mm2(torch.eye(3), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtyping` handles constant dimensions and scalar return types as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def intdot2(A: TensorType[2, int], B: TensorType[int]) -> int:\n",
    "    return A.dot(B).item()\n",
    "\n",
    "# [0, 1] . [1, 2]\n",
    "intdot2(torch.arange(2), torch.arange(2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [float, float] . [float, float]\n",
    "intdot2(torch.randn((2,)), torch.randn((2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [long, long, long] . [long, long, long]\n",
    "intdot2(torch.randn((3,)).long(), torch.randn((3,)).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtyping` can return a scalar tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def scalar_intdot2(A: TensorType[2, int], B: TensorType[int]) -> TensorType[()]:\n",
    "    return A.dot(B)\n",
    "\n",
    "scalar_intdot2(torch.arange(2), torch.arange(2)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to handle group a sequence of dimensions together as a single tuple, use `<dimension group name>: ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds one to the whole tensor without changing its shape.\n",
    "\n",
    "@typechecked\n",
    "def add_one(x: TensorType['dims': ...]) -> TensorType['dims': ...]:\n",
    "    return x + 1\n",
    "\n",
    "add_one(torch.arange(6).reshape((1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def bad_add_one(x: TensorType['dims': ...]) -> TensorType['dims': ...]:\n",
    "    return (x + 1).squeeze() # could reduce number of dimensions\n",
    "\n",
    "bad_add_one(torch.arange(6).reshape((1,2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtyping limitations\n",
    "\n",
    "#### 1. No real linting support with `mypy` or `flake8`\n",
    "\n",
    "Add `# noqa` everywhere to make linters stop complaining. [This is documented](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "\n",
    "#### 2. Types aren't static and have no static type checking support.\n",
    "\n",
    "[This is documented](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "    \n",
    "##### BUT I want static tensor type-checking!\n",
    "\n",
    "You can test sensitive functions with unit tests. Define unit tests with the `@typechecked` decorator, to be run with `pytest` using the `--torchtyping-patch-typeguard` option:\n",
    "\n",
    "```bash\n",
    "pytest --torchtyping-patch-typeguard --tb=short\n",
    "```\n",
    "\n",
    "##### _NO_ I want _actual_ static type checking\n",
    "\n",
    "Check out PyTorch's [named tensors](https://pytorch.org/docs/stable/named_tensor.html#creating-named-tensors) or HarvardNLP's [NamedTensor](https://github.com/harvardnlp/NamedTensor).\n",
    "\n",
    "#### 3. Types aren't strong\n",
    "\n",
    "`torchtyping` doesn't enforce **strong** types on tensors. I.e. tensors aren't required to strictly have the specified named dimensions in order to execute the program.\n",
    "\n",
    "Strongly-typed tensors are enabled by PyTorch's own [`named tensors`](https://pytorch.org/docs/stable/named_tensor.html#creating-named-tensors).\n",
    "\n",
    "Named dimensions also propagate (generally) with `named tensors.\n",
    "\n",
    "E.g.\n",
    "\n",
    "```python\n",
    ">>> x = torch.randn(3, 3, names=('N', 'C'))\n",
    ">>> x.abs().names\n",
    "('N', 'C')\n",
    "```\n",
    "\n",
    "**However** there are some caveats PyTorch's `named tensors`:\n",
    "\n",
    "* Still experimental and has been for several years. The feature is on [hiatus](https://github.com/pytorch/pytorch/issues/60832), and [may be deprecated entirely](https://github.com/pytorch/pytorch/pull/76093).\n",
    "\n",
    "* You lose the convenience of dynamic typing with Python.\n",
    "\n",
    "* Named dimensions [do not propagate through `autograd`](https://pytorch.org/docs/stable/named_tensor.html#autograd-support).\n",
    "\n",
    "## Good News\n",
    "\n",
    "Fortunately lots of these limitations are documented and being explored by the `torchtyping` author. See [here](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "\n",
    "Also [PEP 646](https://peps.python.org/pep-0646/) is coming in [Python 3.11](https://mail.python.org/archives/list/python-dev@python.org/message/OR5RKV7GAVSGLVH3JAGQ6OXFAXIP5XDX/)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cca148b5353471b849fbf4840c527db4fc5ba12d54737a53f883d848a0e2773"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
