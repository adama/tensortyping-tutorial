{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtyping\n",
    "\n",
    "Quick tutorial of runtime type-checking for PyTorch tensors. [Github link](https://github.com/patrick-kidger/torchtyping/blob/master/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtyping \n",
    "!pip install torch --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gripes\n",
    "\n",
    "#### Are you sick of tensor shape errors in your code?\n",
    "#### Do you want to more interpretable error messages on shape mismatches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn((4, 4))\n",
    "x = torch.randn((16, 4, 4))\n",
    "torch.bmm(weight, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn((1, 4, 4))\n",
    "x = torch.randn((16, 4, 4))\n",
    "torch.bmm(weight, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are you frustrated by poor tensor shape documentation?\n",
    "\n",
    "```python\n",
    "\n",
    "embed = Embedding(x) # [batch, seq, dim]    descriptive\n",
    "layer1 = Layer1(embed) # [b, s, d]          terse\n",
    "layer2 = Layer2(layer1) # batch first       what are the other dimensions?\n",
    "logits = FunkyLayer(layer2) #               no annotation at all!\n",
    "\n",
    "def foo(x: torch.Tensor) -> torch.Tensor: # like... obviously?\n",
    "    return x\n",
    "``` \n",
    "\n",
    "#### Are `asserts` your only defense against shape mismatches?\n",
    "\n",
    "```python\n",
    "HIDDEN_DIM = 1024\n",
    "logits = my_op(input)\n",
    "assert logits.size(-1 == HIDDEN_DIM\n",
    "```\n",
    "\n",
    "#### Do you only want to type check when you have to?\n",
    "\n",
    "```python\n",
    "def complex_op(t):  # we want to document this!\n",
    "    ...\n",
    "\n",
    "def clamper(t):     # not worth documenting or checking\n",
    "    return torch.clamp(t, max=1.0)\n",
    "```\n",
    "\n",
    "#### Do you want to check for valid shapes in unit tests before loading a massive model into memory?\n",
    "\n",
    "#### Do you want to avoid the effort of annotating an entire codebase or implementing statically-enforced tensor types?\n",
    "\n",
    "#### What if you're locked to a particular Python or torch version and don't want to upgrade to get experimental support for named tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEHOLD [torchtyping](https://github.com/patrick-kidger/torchtyping)\n",
    "\n",
    "Turn this:\n",
    "```python\n",
    "def batch_outer_product(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    # x has shape (batch, x_channels)\n",
    "    # y has shape (batch, y_channels)\n",
    "    # return has shape (batch, x_channels, y_channels)\n",
    "\n",
    "    return x.unsqueeze(-1) * y.unsqueeze(-2)\n",
    "```\n",
    "into this:\n",
    "```python\n",
    "@typechecked\n",
    "def batch_outer_product(x:   TensorType[\"batch\", \"x_channels\"],\n",
    "                        y:   TensorType[\"batch\", \"y_channels\"]\n",
    "                        ) -> TensorType[\"batch\", \"x_channels\", \"y_channels\"]:\n",
    "\n",
    "    return x.unsqueeze(-1) * y.unsqueeze(-2)\n",
    "```\n",
    "\n",
    "(^ shamelessly stolen from the project's [readme](https://github.com/patrick-kidger/torchtyping/blob/master/README.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "Remember type annotations (\"type hints\") in Python are completely optional: they aren't enforced statically or at runtime.\n",
    "```python\n",
    "def foo(bar: int) -> int:\n",
    "    return 42\n",
    "```\n",
    "\n",
    "`mypy` allows optional _static_ type-checking.\n",
    "\n",
    "Use `patch_typeguard` in your module to enforce tensor type checking at _runtime_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtyping import TensorType, patch_typeguard\n",
    "from typeguard import typechecked\n",
    "\n",
    "patch_typeguard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _generic_ type can be specified with a `TypeVar` and used as a type annotation. e.g. \n",
    "```\n",
    "from typing import List\n",
    "x: List[int] = [1, 2, 3]\n",
    "```\n",
    "\n",
    "This is an example of a _variadic_ generic type. \n",
    "Variadic generics were proposed in [PEP 646](https://peps.python.org/pep-0646/) and are [coming in Python 3.11](https://mail.python.org/archives/list/python-dev@python.org/message/OR5RKV7GAVSGLVH3JAGQ6OXFAXIP5XDX/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def mm(A: TensorType['m','n'], B: TensorType['m','p']) -> TensorType['n','p']:\n",
    "    return A.T @ B\n",
    "\n",
    "mm(torch.eye(3), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does an error look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm(torch.eye(4), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about matrix-vector multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm(torch.eye(4), torch.arange(4).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensortyping` has support for `Union` and `Optional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "@typechecked\n",
    "def mm2(A: TensorType['m','n'], B: Union[TensorType['m','p'], TensorType['m']] ) -> Union[TensorType['n','p'], TensorType['n']]:\n",
    "    return A.T @ B\n",
    "\n",
    "mm2(torch.eye(3), torch.arange(3).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm2(torch.eye(3), torch.arange(6).float().reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handles constant dimensions and scalar return types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def intdot2(A: TensorType[2, int], B: TensorType[int]) -> int:\n",
    "    return A.dot(B).item()\n",
    "\n",
    "intdot2(torch.arange(2), torch.arange(2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intdot2(torch.randn((2,)), torch.randn((2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intdot2(torch.randn((3,)).long(), torch.randn((3,)).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can return a scalar tensor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def scalar_intdot2(A: TensorType[2, int], B: TensorType[int]) -> TensorType[()]:\n",
    "    return A.dot(B)\n",
    "\n",
    "scalar_intdot2(torch.arange(2), torch.arange(2)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to handle an arbitrary number of dimensions as a single tuple, use `<name>: ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def add_one(x: TensorType['d': ...]) -> TensorType['d': ...]:\n",
    "    return x + 1\n",
    "\n",
    "add_one(torch.arange(6).reshape((1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def bad_add_one(x: TensorType['d': ...]) -> TensorType['d': ...]:\n",
    "    return (x + 1).squeeze()\n",
    "\n",
    "bad_add_one(torch.arange(6).reshape((1,2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtyping limitations\n",
    "\n",
    "1. No linting support (with `mypy` or `flake8`). [This is documented](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "\n",
    "1. No static type checking support. [This is documented](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "    \n",
    "    **BUT I want static tensor type-checking!**\n",
    "\n",
    "    You can simulate this. Define unit tests to run with `pytest`, using the `@typechecked` decorator, and invoking `pytest` like this:\n",
    "    ```bash\n",
    "    pytest --torchtyping-patch-typeguard --tb=short\n",
    "    ```\n",
    "\n",
    "    **_NO_ I want _actual_ static type checking**\n",
    "    \n",
    "    Check out PyTorch's [named tensors](https://pytorch.org/docs/stable/named_tensor.html#creating-named-tensors) or HarvardNLP's [NamedTensor](https://github.com/harvardnlp/NamedTensor).\n",
    "\n",
    "1. Types aren't strong and don't propagate like PyTorch's own [named tensors](https://pytorch.org/docs/stable/named_tensor.html#creating-named-tensors)\n",
    "    E.g. named dimensions with\n",
    "    ```python\n",
    "    >>> x = torch.randn(3, 3, names=('N', 'C'))\n",
    "    >>> x.abs().names\n",
    "    ('N', 'C')\n",
    "    ```\n",
    "\n",
    "    *HOWEVER*\n",
    "    * Named tensors are still experimental (have been for several years), is on [hiatus](https://github.com/pytorch/pytorch/issues/60832), and [may be deprecated entirely](https://github.com/pytorch/pytorch/pull/76093).\n",
    "    * You lose the convenience of dynamic typing with Python.\n",
    "    * Named dimensions [do not propagate through `autograd`](https://pytorch.org/docs/stable/named_tensor.html#autograd-support).\n",
    "\n",
    "Fortunately lots of these are documented and being explored by the `torchtyping` author. See [here](https://github.com/patrick-kidger/torchtyping/blob/master/FURTHER-DOCUMENTATION.md).\n",
    "Also [PEP 646](https://peps.python.org/pep-0646/) is coming in [Python 3.11](https://mail.python.org/archives/list/python-dev@python.org/message/OR5RKV7GAVSGLVH3JAGQ6OXFAXIP5XDX/)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cca148b5353471b849fbf4840c527db4fc5ba12d54737a53f883d848a0e2773"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
